vars:
  - stage: newlang
  - baselanguages: "en de es fr it"
  - newlanguages: "pt"
  - newlanguages_list: ["pt"]
  - clwepivot: "en"
  - embdim: 300
  - model: "continuous"
  - baseconfig: "train-base"
  - basemodel: "models/base_avg.pt"
  - autoencoderconfig: "train"

stages:
  # set_stage "newlang"
  #download_embeddings:
  #  cmd: download_embeddings "${newlanguages}"
  #  wdir: "embeddings/models"
  #  deps:
  #  - "/dev/null"
  #  outs:
  #  - "./"
  download_embeddings:
    foreach: ${newlanguages_list}
    do:
      cmd: download_embeddings "${item}"
      wdir: "embeddings/models"
      deps:
      - "/dev/null"
      outs:
      - "cc.${item}.${embdim}.vec"
      - "cc.${item}.${embdim}.bin"

  compute_alignments:
    cmd: compute_alignments "${clwepivot}" "${newlanguages}"
    wdir: "embeddings"
    deps:
    - "models/"
    outs:
    - "dicts/"
    - "align/"

  extract_data:
    cmd: extract_data "${baselanguages} ${newlanguages}"
    wdir: "data"
    deps:
    - "ted_talks.tar.gz"
    outs:
    - "extracted/"

  prepare_monolingual_data:
    cmd: dsets="train dev" prepare_monolingual_data "${newlanguages}"
    wdir: "data"
    deps:
    - "extracted/"
    outs:
    - "monolingual/"

  build_embeddings:
    cmd: build_embeddings "${newlanguages}"
    deps:
    #- "extract-words.py"
    - "data/monolingual/"
    - "embeddings/align/"
    - "embeddings/models/"
    outs:
    - "data/embeddings/"

  # set_stage "blindenc"
  prepare_parallel_data:
    cmd: prepare_parallel_data "test" "${baselanguages} ${newlanguages}"
    wdir: "data"
    deps:
    - "extracted/"
    outs:
    - "parallel/"

  evauate_bleu_blindenc:
    cmd: evauate_bleu "blindenc" "${newlanguages}" "${baselanguages}"
    deps:
    - "models/blindenc_avg.pt"
    #- "data/eval/"
    - "data/parallel/"
    - "data/embeddings/"
    outs:
    - "translations/blindenc/"
    - "scores/blindenc/"

  evauate_bleu_blinddec:
    cmd: evauate_bleu "blinddec" "${baselanguages}" "${newlanguages}"
    deps:
    - "models/blinddec_avg.pt"
    #- "data/eval/"
    - "data/parallel/"
    - "data/embeddings/"
    outs:
    - "translations/blinddec/"
    - "scores/blinddec/"

  # set_stage "autoencoder"
  build_newlang_vocab:
    cmd: build_newlang_vocab "${basemodel}" "${newlanguages}" "${newlanguages}"
    deps:
    - "${basemodel}"
    - "data/embeddings/"
    outs:
    - "saves/data.vocab.pt"
    - "saves/specials.pt"

  concat_autoencoding_corpus:
    cmd: concat_autoencoding_corpus "autoencoder" "${newlanguages}"
    wdir: "data"
    deps:
    - "monolingual/"
    outs:
    - "corpus/"

  preprocess_reuse_vocab:
    cmd: preprocess_reuse_vocab "autoencoder" "saves/data.vocab.pt"
    deps:
    - "data/corpus/"
    - "saves/data.vocab.pt"
    outs:
    - "saves/autoencoder/"

  train_continue_autoencode:
    cmd: train_continue "autoencoder" "${model}" "${autoencoderconfig}" "${basemodel}"
    deps:
    - "saves/autoencoder/"
    - "${basemodel}"
    outs:
    - "models/autoencoder/"
    metrics:
    - "logs/autoencoder/"

  average_models_autoencode:
    cmd: onmt_average_models -m models/autoencoder/*.pt -o models/autoencoder_avg.pt
    deps:
    - "models/autoencoder/"
    outs:
    - "models/autoencoder_avg.pt"

  evauate_bleu_autoencode:
    cmd: evauate_bleu "autoencoder" "${baselanguages}" "${newlanguages}"
    deps:
    - "models/autoencoder_avg.pt"
    - "data/parallel/"
    outs:
    - "translations/autoencoder/"
    - "scores/autoencoder/"

  # set_stage "backtranslate"
  prepare_backtranslation_data_round1:
    cmd: prepare_backtranslation_data "$data_in" "${baselanguages}" "${newlanguages}"
    deps:
    - "data/raw/monolingual/"
    outs:
    - "data/bt/src/round1/"

  backtranslation_round_round1:
    cmd: freezeenc=y backtranslation_round "$basemodel" "$btmodel" "${baselanguages}" "${newlanguages}"
    deps:
    - "data/bt/src/round1/"
    - "models/bt/round0/"
    - "models/bt/basemodel/"
    outs:
    #- "data/bt/tgt/round1/"
    - "models/bt/round1/"

  evauate_bleu_backtranslation_round1:
    cmd: evauate_bleu "backtranslate" "$btmodel" "${baselanguages}" "${newlanguages}"
    deps:
    - "models/bt/round1/"
    - "models/backtranslate/round1/"
    - "data/eval/"
    outs:
    - "translations/backtranslate/round1/"
    - "scores/backtranslate/round1/"

  prepare_backtranslation_data_round2:
    cmd: prepare_backtranslation_data "$data_in" "${newlanguages}" "${baselanguages}"
    deps:
    - "data/raw/monolingual/"
    outs:
    - "data/bt/src/round2/"

  backtranslation_round_round2:
    cmd: freezeenc= backtranslation_round "$basemodel" "$btmodel" "${newlanguages}" "${baselanguages}"
    deps:
    - "data/bt/src/round2/"
    - "models/bt/round1/"
    - "models/bt/basemodel/"
    outs:
    #- "data/bt/tgt/round2/"
    - "models/bt/round2/"

  evauate_bleu_backtranslation_round2:
    cmd: evauate_bleu "backtranslate" "$btmodel" "${newlanguages}" "${baselanguages}"
    deps:
    - "models/bt/round2/"
    - "models/backtranslate/round2"
    - "data/eval/"
    outs:
    - "translations/backtranslate/round2/"
    - "scores/backtranslate/round2/"
